# -*- coding: utf-8 -*-
"""federated_training.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RWyzmNxCNGsF1Pna2-NYgOxeD1X8Pxpq
"""

import tensorflow as tf
import tensorflow_federated as tff
import pandas as pd
import numpy as np
import os
from model import create_model # Import from our model.py

# --- Configuration ---
CLIENT_DATA_PATH = './client_data/'
NUM_CLIENTS = 10
NUM_ROUNDS = 50
CLIENTS_PER_ROUND = 5
LOCAL_EPOCHS = 3
BATCH_SIZE = 32
MODEL_SAVE_PATH = 'models/global_model.h5'
# --- End Configuration ---

# 1. Load Client Data (Simulation)
# In a real TFF setup, this would be more complex.
# Here, we create a list of tf.data.Dataset objects.
def load_client_data():
    """Loads client data manifests and prepares TFF Datasets."""
    client_data = []
    for i in range(NUM_CLIENTS):
        client_dir = os.path.join(CLIENT_DATA_PATH, f'client_{i}')
        df = pd.read_csv(os.path.join(client_dir, 'data.csv'))

        # This is a placeholder. A real implementation would:
        # 1. Load images from disk using df['Image Index']
        # 2. Preprocess images (resize, normalize)
        # 3. Multi-hot encode the 'Finding Labels'
        # 4. Create a tf.data.Dataset

        # For this example, we create dummy data
        dummy_images = np.random.rand(len(df), 224, 224, 3).astype(np.float32)
        dummy_labels = np.random.randint(0, 2, (len(df), 14)).astype(np.float32)

        dataset = tf.data.Dataset.from_tensor_slices((dummy_images, dummy_labels))
        dataset = dataset.batch(BATCH_SIZE).repeat(LOCAL_EPOCHS)
        client_data.append(dataset)

    print(f"Loaded simulated data for {len(client_data)} clients.")
    return client_data

# 2. Define TFF Computations
def model_fn():
    """Tells TFF how to create the model."""
    keras_model = create_model()
    return tff.learning.from_keras_model(
        keras_model,
        # Dummy batch for input spec
        input_spec=train_data[0].element_spec,
        loss=tf.keras.losses.BinaryCrossentropy(),
        metrics=[tf.keras.metrics.BinaryAccuracy()])

# 3. Main Training Orchestration
if __name__ == "__main__":
    print("Starting Federated Training Process...")

    # Load data
    train_data = load_client_data()

    # Initialize the Federated Averaging process
    # This creates the `client_update` and `server_update` functions
    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn,
        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)
    )

    # Initialize the server state (global model weights)
    state = iterative_process.initialize()

    # 4. Run the Training Loop
    print(f"Starting training for {NUM_ROUNDS} rounds...")
    for round_num in range(1, NUM_ROUNDS + 1):
        # Select a subset of clients for this round
        client_subset = np.random.choice(train_data, CLIENTS_PER_ROUND, replace=False)

        # Run one round of training
        state, metrics = iterative_process.next(state, client_subset)

        print(f"Round {round_num}/{NUM_ROUNDS} - Metrics: {metrics['train']}")

    # 5. Save the Final Global Model
    print("Training complete. Saving final global model...")

    # Extract the final Keras model from the server state
    final_keras_model = create_model()
    # Get weights from TFF state and set them in the Keras model
    tff.learning.ModelWeights.from_model(final_keras_model).assign_weights_to(state.model)

    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
    final_keras_model.save(MODEL_SAVE_PATH)

    print(f"Model saved to {MODEL_SAVE_PATH}")